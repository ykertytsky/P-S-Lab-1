log(100); log10(100); log(100,10)     # logarithms
sin(pi/2); tan(pi/2)                  # trig
sqrt(1/2^2)                           # squares and roots
exp(cos(pi/2))                        # exponents
log(100)     # logarithms
sin(pi/2); tan(pi/2)                  # trig
sqrt(1/2^2)                           # squares and roots
exp(cos(pi/2))                        # exponents
# increasing sequences
1:10; seq(1,10); c(1,2,3,4,5,6,7,8,9,10)
# decreasing sequences
10:1; seq(10,1); seq(10,1,by=-1); seq(10,1,length=10)
# sequences with rep = repeat
rep(1:5,3); rep(1:5,each=3); rep(1:5,c(3,3,3,3,3)); rep(1:5,rep(3,5));
rep(1:5, length.out = 13)
# yet another way
vctr <- seq(0,1,by=.1); seq(1:length(vctr)); seq(along = vctr)
a <- seq(-1, 1, length=5); a; a^2; 2*a
#  can you guess what 2^a is?
print("Can you quess what 2^a is?"); 2^a
# indexing
a[1]; a[-1]
a[c(5,1)]; a[-c(5,1)]
# operations with 2 sequences
b <- c(4,-1,1,2,4); b
a+b; a^b
# logical
a>0; a[a>0]; sum(a<=0)
# changing vectors
a <- 1/a; a
a[3] <- b[3]; a; b[3]
1:100
a <- seq(-1, 2, length=100);
a <- seq(-1, 2, length=100);
a
# 1
a <- seq(-1, 2, length=100);
# 2
b <- a[1]
# 1
a <- seq(-1, 2, length=100);
# 2
b <- a[1]
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[-1], lenght=100)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[-1], length=100)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], 1, length=100)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], 1, length=100)
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[length(a)], length=100)
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[length(a)], length=50)
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[length(a)], length=50)
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[length(a)], length=100)
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[length(a)], by=2 length=100)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[length(a)], by=2, length=100)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by = 2)]
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by = 2)]
b <- seq(a[1], a[length(a)], by=2, length=100)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by = 2)]
# b <- seq(a[1], a[length(a)], by=2, length=100)
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- seq(a[1], a[length(a)], by=2)
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[1, lenght(a), by=2]
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[1, length(a), by=2]
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
ab
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
ab = a*b
ab
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
ab = a*b
ab.mean()
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
ab = a*b
mean(ab)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
ab = a*b
mean(ab)
variance(ab)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
ab = a*b
mean(ab)
var(a, b)
# 1
a <- seq(-2, 1, length=100);
# 2
b <- a[seq(1, length(a), by=2)]
# sum
ab = a + b
ab = a-b
ab = a*b
mean(ab)
var(ab)
# --- Build Bag-of-Words DTM (docs x vocab) with base R ---
dtm <- xtabs(n ~ doc_id + word, data = counts)
dtm <- as.matrix(dtm)  # numeric matrix
# --- Quick peeks ---
dim(dtm)                 # docs x vocab
if (ncol(dtm) >= 10) colnames(dtm)[1:10] else colnames(dtm)
if (nrow(dtm) >= 1 && ncol(dtm) >= 10) dtm[1, 1:10] else NULL
head(doc_index)
# --- Tokenize -> one row per (doc_id, word) ---
# IMPORTANT: pass df as the first (positional) argument; don't use data=...
df_tokens <- tidytext::unnest_tokens(
df,
output = "word",
input  = "Message",
token  = "words",
to_lower = FALSE   # already lowercased above
)
# --- Remove stop words ---
df_tokens <- dplyr::anti_join(df_tokens, stop_wrds, by = "word")
print(head(doc_index))
print(head(doc_index))
# Step 3: build the Bag-of-Words (DTM) with base R (no tidyr)
# rows = doc_id, cols = word, values = n
dtm <- xtabs(n ~ doc_id + word, data = counts)
dtm <- as.matrix(dtm)   # ensure it's a numeric matrix
cat("This is your bag-of-words representation ready for machine learning!\n")
source("~/Documents/Studying/P&S/LAb1/data_preprocessing.R", echo = TRUE)
ggplot(word_df[1:15, ], aes(x = reorder(word, frequency), y = frequency)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 15 Most Frequent Words",
x = "Words", y = "Frequency") +
theme_minimal()
# VISUALIZATION (optional)
create_word_frequency_plot <- function(top_words) {
word_df <- data.frame(
word = names(top_words),
frequency = as.numeric(top_words),
stringsAsFactors = FALSE
)
ggplot(word_df[1:15, ], aes(x = reorder(word, frequency), y = frequency)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 15 Most Frequent Words",
x = "Words", y = "Frequency") +
theme_minimal()
}
View(datasets)
exit
exit()
